name: Deploy to Lightsail

on:
  push:
    branches: [ "master", "main" ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - name: Deploy over SSH
        uses: appleboy/ssh-action@v1.0.3
        timeout-minutes: 14
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          SSL_ORIGIN: ${{ secrets.SSL_ORIGIN }}
          SSL_PRIVATE: ${{ secrets.SSL_PRIVATE }}
        with:
          host: ${{ secrets.LIGHTSAIL_HOST }}
          username: deploy
          key: ${{ secrets.LIGHTSAIL_SSH_KEY }}
          envs: AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,SSL_ORIGIN,SSL_PRIVATE
          script: |
            set -e
            APP_NAME=watch-party
            APP_DIR=/srv/$APP_NAME
            
            # Clone or update repo
            if [ ! -d "$APP_DIR" ]; then
              git clone https://github.com/EL-HOUSS-BRAHIM/watch-party.git $APP_DIR
              cd $APP_DIR
            else
              cd $APP_DIR
              git fetch origin
              git reset --hard origin/master
            fi
            
            # Generate production environment files from templates
            echo "üîß Setting up production environment files..."
            
            # Generate backend .env for production
            echo "üìù Creating backend/.env for production..."
            cat > backend/.env << 'BACKEND_ENV'
            # WATCH PARTY BACKEND - PRODUCTION CONFIGURATION
            DEBUG=False
            SECRET_KEY=your-super-secret-key-here-change-in-production
            DJANGO_SETTINGS_MODULE=config.settings.production
            ALLOWED_HOSTS=35.181.116.57,be-watch-party.brahim-elhouss.me,watch-party.brahim-elhouss.me,localhost,127.0.0.1
            
            # DATABASE CONFIGURATION (AWS RDS PostgreSQL)
            DATABASE_URL=postgresql://watchparty_admin:your_secure_password@watch-party-postgres.cj6w0queklir.eu-west-3.rds.amazonaws.com:5432/watchparty_prod?sslmode=require
            DB_NAME=watchparty_prod
            DB_USER=watchparty_admin
            DB_PASSWORD=your_secure_password
            DB_HOST=watch-party-postgres.cj6w0queklir.eu-west-3.rds.amazonaws.com
            DB_PORT=5432
            DB_SSL_MODE=require
            
            # REDIS CONFIGURATION (AWS ElastiCache Valkey - using dynamic AWS Secrets Manager)
            REDIS_HOST=master.watch-party-valkey.2muo9f.euw3.cache.amazonaws.com
            REDIS_PORT=6379
            REDIS_USE_SSL=True
            
            # SECURITY SETTINGS
            SECURE_SSL_REDIRECT=True
            SESSION_COOKIE_SECURE=True
            CSRF_COOKIE_SECURE=True
            SECURE_HSTS_SECONDS=31536000
            SECURE_HSTS_INCLUDE_SUBDOMAINS=True
            SECURE_HSTS_PRELOAD=True
            
            # AWS S3 CONFIGURATION
            USE_S3=true
            AWS_STORAGE_BUCKET_NAME=your-s3-bucket-name
            AWS_S3_REGION_NAME=eu-west-3
            
            # CORS CONFIGURATION
            CORS_ALLOWED_ORIGINS=https://watch-party.brahim-elhouss.me,https://be-watch-party.brahim-elhouss.me
            
            # ENVIRONMENT
            ENVIRONMENT=production
            
            # FEATURE FLAGS
            MAINTENANCE_MODE=False
            REGISTRATION_ENABLED=True
            GOOGLE_DRIVE_INTEGRATION_ENABLED=True
            YOUTUBE_INTEGRATION_ENABLED=True
            TWO_FACTOR_AUTH_ENABLED=True
            
            # EMAIL CONFIGURATION
            EMAIL_BACKEND=django.core.mail.backends.console.EmailBackend
            DEFAULT_FROM_EMAIL=noreply@watchparty.com
            
            # JWT AUTHENTICATION
            JWT_SECRET_KEY=your-jwt-secret-key-change-this
            JWT_REFRESH_SECRET_KEY=your-jwt-refresh-secret-key-change-this
            JWT_ACCESS_TOKEN_LIFETIME=60
            JWT_REFRESH_TOKEN_LIFETIME=7
            
            # OTHER PRODUCTION SETTINGS
            RATE_LIMIT_LOGIN=5/min
            RATE_LIMIT_API=1000/hour
            RATE_LIMIT_UPLOAD=10/hour
            BACKEND_ENV
            
            # Generate frontend .env.local for production
            echo "üìù Creating frontend/.env.local for production..."
            cat > frontend/.env.local << 'FRONTEND_ENV'
            # Production Frontend Environment Variables
            NEXT_PUBLIC_API_URL=https://be-watch-party.brahim-elhouss.me
            NEXT_PUBLIC_WS_URL=wss://be-watch-party.brahim-elhouss.me/ws
            
            # Feature Flags
            NEXT_PUBLIC_ENABLE_GOOGLE_DRIVE=true
            NEXT_PUBLIC_ENABLE_DISCORD=true
            NEXT_PUBLIC_ENABLE_ANALYTICS=true
            FRONTEND_ENV
            
            echo "‚úÖ Production environment files created"
            echo "üîç Verifying Django settings module..."
            if grep -q "DJANGO_SETTINGS_MODULE=config.settings.production" backend/.env; then
              echo "‚úÖ DJANGO_SETTINGS_MODULE correctly set to config.settings.production"
            else
              echo "‚ö†Ô∏è  Warning: DJANGO_SETTINGS_MODULE configuration issue"
            fi
            
            # Configure AWS CLI (required for AWS external services)
            if ! command -v aws &> /dev/null; then
              echo "üì¶ Installing AWS CLI..."
              curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
              unzip -o -q awscliv2.zip
              
              # Install AWS CLI in user's home directory (no sudo needed)
              echo "Installing AWS CLI for current user (deploy)..."
              ./aws/install --install-dir $HOME/aws-cli --bin-dir $HOME/aws-cli-bin --update
              
              # Add to PATH for this session
              export PATH="$HOME/aws-cli-bin:$PATH"
              echo 'export PATH="$HOME/aws-cli-bin:$PATH"' >> ~/.bashrc
              
              rm -rf aws awscliv2.zip
              echo "‚úÖ AWS CLI installed: $(aws --version)"
            else
              echo "‚úÖ AWS CLI already installed: $(aws --version)"
            fi
            
            # Configure AWS credentials and region for Secrets Manager access
            mkdir -p ~/.aws
            cat > ~/.aws/config << 'AWSCONFIG'
            [default]
            region = eu-west-3
            output = json
            AWSCONFIG
            
            # Configure AWS credentials if provided via environment variables
            # (these would be set from GitHub Actions secrets)
            if [ -n "${AWS_ACCESS_KEY_ID:-}" ] && [ -n "${AWS_SECRET_ACCESS_KEY:-}" ]; then
              echo "üîß Configuring AWS credentials from environment variables..."
              cat > ~/.aws/credentials << 'AWSCREDS'
            [default]
            aws_access_key_id = ${AWS_ACCESS_KEY_ID}
            aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}
            AWSCREDS
              chmod 600 ~/.aws/credentials
            else
              echo "üîß Using IAM role for AWS access (no credentials file needed)"
            fi
            
            # Test AWS connectivity
            echo "üîç Testing AWS connectivity..."
            if ! aws sts get-caller-identity > /dev/null 2>&1; then
              echo "‚ùå AWS configuration failed."
              echo "   Either configure AWS credentials in GitHub secrets (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)"
              echo "   OR ensure IAM role MyAppRole is attached to this server."
              exit 1
            fi
            echo "‚úÖ AWS connectivity confirmed"
            
            # Test Secrets Manager access (required for app configuration)
            echo "üîç Testing Secrets Manager access..."
            if aws secretsmanager get-secret-value --secret-id all-in-one-credentials --region eu-west-3 > /dev/null 2>&1; then
              echo "‚úÖ AWS Secrets Manager access confirmed"
            else
              echo "‚ö†Ô∏è  Secrets Manager access test failed - check permissions"
              echo "   The app needs access to secrets like 'all-in-one-credentials'"
            fi
            
            # Configure SSL certificates for HTTPS
            echo "üîê Setting up SSL certificates..."
            sudo mkdir -p /etc/nginx/ssl
            
            # Check if SSL certificates already exist
            if [ -f "/etc/nginx/ssl/origin.pem" ] && [ -f "/etc/nginx/ssl/private.key" ]; then
              echo "‚úÖ SSL certificates already exist"
            else
              echo "üìù Creating SSL certificates from GitHub secrets..."
              
              # Create origin certificate from SSL_ORIGIN secret
              if [ -n "${SSL_ORIGIN:-}" ]; then
                echo "$SSL_ORIGIN" | sudo tee /etc/nginx/ssl/origin.pem > /dev/null
                sudo chmod 644 /etc/nginx/ssl/origin.pem
                echo "‚úÖ SSL origin certificate created"
              else
                echo "‚ö†Ô∏è  SSL_ORIGIN secret not provided - HTTPS will not work"
              fi
              
              # Create private key from SSL_PRIVATE secret
              if [ -n "${SSL_PRIVATE:-}" ]; then
                echo "$SSL_PRIVATE" | sudo tee /etc/nginx/ssl/private.key > /dev/null
                sudo chmod 600 /etc/nginx/ssl/private.key
                echo "‚úÖ SSL private key created"
              else
                echo "‚ö†Ô∏è  SSL_PRIVATE secret not provided - HTTPS will not work"
              fi
              
              # Verify SSL certificate files
              if [ -f "/etc/nginx/ssl/origin.pem" ] && [ -f "/etc/nginx/ssl/private.key" ]; then
                echo "üîç Verifying SSL certificate..."
                if sudo openssl x509 -in /etc/nginx/ssl/origin.pem -noout -text > /dev/null 2>&1; then
                  echo "‚úÖ SSL certificate is valid"
                else
                  echo "‚ö†Ô∏è  SSL certificate validation failed"
                fi
              fi
            fi
            
            # Build and deploy with Docker Compose (uses external AWS services)
            echo "üèóÔ∏è  Building Docker images with optimizations..."
            
            # Enable Docker BuildKit for better caching and parallel builds
            export DOCKER_BUILDKIT=1
            export COMPOSE_DOCKER_CLI_BUILD=1
            export BUILDKIT_PROGRESS=plain
            
            # Clean up old containers first
            docker-compose down --remove-orphans || true
            
            # Build images in parallel with optimized caching
            echo "üì¶ Building images in parallel..."
            export DOCKER_BUILDKIT=1
            export COMPOSE_DOCKER_CLI_BUILD=1
            export BUILDKIT_PROGRESS=plain
            # Set environment variable to skip AWS calls during build
            export SKIP_AWS_DURING_BUILD=1
            
            timeout 1200 docker-compose build --parallel --build-arg BUILDKIT_INLINE_CACHE=1 --build-arg SKIP_AWS_DURING_BUILD=1 || {
              echo "‚ö†Ô∏è Parallel build failed, trying sequential build..."
              
              # Build backend first (faster and required by others)
              echo "üì¶ Building backend image..."
              if ! timeout 600 docker-compose build backend --build-arg SKIP_AWS_DURING_BUILD=1; then
                echo "‚ùå Backend build failed"
                exit 1
              fi
              
              # Build frontend with optimized settings and compatibility timeout
              echo "üì¶ Building frontend image..."
              if ! timeout 1200 docker-compose build frontend \
                --build-arg NODE_OPTIONS="--max-old-space-size=2048" \
                --build-arg SKIP_AWS_DURING_BUILD=1; then
                echo "‚ùå Frontend build failed"
                exit 1
              fi
            }
            
            echo "‚úÖ All images built successfully"
            
            # Start services in optimized stages
            echo "üöÄ Starting backend service..."
            docker-compose up -d backend
            
            # Improved backend readiness checking with multiple fallbacks
            echo "‚è≥ Waiting for backend to be ready..."
            backend_ready=false
            
            for i in {1..30}; do
              # Try multiple health check methods
              if docker-compose exec -T backend python manage.py check --deploy > /dev/null 2>&1; then
                echo "‚úÖ Backend Django checks passed"
                backend_ready=true
                break
              elif curl -f -s http://localhost:8000/health/ > /dev/null 2>&1; then
                echo "‚úÖ Backend HTTP health check passed"
                backend_ready=true
                break
              elif docker-compose exec -T backend python -c "import django; django.setup()" > /dev/null 2>&1; then
                echo "‚úÖ Backend Django can be imported"
                backend_ready=true
                break
              else
                echo "‚è≥ Waiting for backend... ($i/30)"
                if [ $i -eq 30 ]; then
                  echo "‚ùå Backend failed to start properly after 90s"
                  echo "üìã Backend container logs:"
                  docker-compose logs --tail=50 backend
                  echo "üìã Backend container status:"
                  docker-compose ps backend
                  echo "üìã Backend environment check:"
                  docker-compose exec -T backend env | grep DJANGO_SETTINGS_MODULE || echo "DJANGO_SETTINGS_MODULE not found"
                  echo "üìã Testing Django configuration:"
                  docker-compose exec -T backend python test_django_config.py 2>&1 || echo "Django config test failed"
                  exit 1
                fi
                sleep 3
              fi
            done
            
            if [ "$backend_ready" = false ]; then
              echo "‚ùå Backend readiness check failed"
              exit 1
            fi
            
            echo "üöÄ Starting all services..."
            docker-compose up -d
            
            # Optimized health checking with shorter intervals
            echo "‚è≥ Waiting for services to be ready..."
            sleep 15
            
            # Improved health checking with detailed diagnostics
            echo "üè• Testing backend health..."
            backend_healthy=false
            
            for i in {1..15}; do
              # Test different health endpoints
              if curl -f -s -m 5 http://localhost:8000/health/ > /dev/null 2>&1; then
                echo "‚úÖ Backend health endpoint responding"
                backend_healthy=true
                break
              elif curl -f -s -m 5 http://localhost:8000/api/health/ > /dev/null 2>&1; then
                echo "‚úÖ Backend API health endpoint responding"
                backend_healthy=true
                break
              elif curl -s -m 5 http://localhost:8000/ | grep -q "API\|Welcome" 2>/dev/null; then
                echo "‚úÖ Backend root endpoint responding"
                backend_healthy=true
                break
              else
                echo "‚è≥ Backend health check... ($i/15)"
                if [ $i -eq 15 ]; then
                  echo "‚ùå Backend health check failed after 7.5 minutes"
                  echo "üìã Detailed backend diagnostics:"
                  echo "=== Backend container logs (last 50 lines) ==="
                  docker-compose logs --tail=50 backend
                  echo "=== Backend container status ==="
                  docker-compose ps backend
                  echo "=== Backend container processes ==="
                  docker-compose exec -T backend ps aux 2>/dev/null || echo "Could not get process list"
                  echo "=== Network connectivity test ==="
                  docker-compose exec -T backend curl -I localhost:8000 2>/dev/null || echo "Local curl failed"
                  echo "=== Django configuration test ==="
                  docker-compose exec -T backend python manage.py check --deploy 2>&1 || echo "Django check failed"
                  exit 1
                fi
                sleep 30
              fi
            done
            
            if [ "$backend_healthy" = false ]; then
              echo "‚ùå Backend health check failed"
              exit 1
            fi
            
            # Test frontend health with reduced wait time
            echo "üè• Testing frontend health..."
            for i in {1..8}; do
              if curl -f -s http://localhost:3000 > /dev/null 2>&1; then
                echo "‚úÖ Frontend is healthy"
                break
              elif [ $i -eq 8 ]; then
                echo "‚ùå Frontend health check failed"
                echo "üìã Frontend logs:"
                docker-compose logs --tail=30 frontend
                exit 1
              else
                echo "‚è≥ Frontend health check... ($i/8)"
                sleep 10
              fi
            done
            
            # Run initial setup if this is first deployment
            if docker-compose exec -T backend python manage.py showmigrations --plan | grep -q "\[ \]"; then
              echo "üîß Running initial Django setup..."
              if ! docker-compose exec -T backend python manage.py migrate; then
                echo "‚ùå Migration failed. Check database connectivity:"
                echo "   - Verify RDS PostgreSQL is accessible"
                echo "   - Check database credentials in backend/.env"
                docker-compose logs backend
                exit 1
              fi
              docker-compose exec -T backend python manage.py collectstatic --noinput
            fi
            
            # Final health check
            echo "üè• Final health check..."
            if curl -f http://localhost:8000/health/ > /dev/null 2>&1; then
              echo "üéâ Deployment successful!"
              echo "   Frontend: https://${{ secrets.LIGHTSAIL_HOST }}/"
              echo "   Backend API: https://${{ secrets.LIGHTSAIL_HOST }}/api/"
              echo "   (HTTP requests will be automatically redirected to HTTPS)"
            else
              echo "‚ùå Final health check failed"
              docker-compose logs --tail=20 backend
              exit 1
            fi
            
            # Cleanup
            docker system prune -f
